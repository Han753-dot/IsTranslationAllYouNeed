{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_dict_list(file_path: str) -> list:\n",
    "\n",
    "    \"\"\"\n",
    "    Transforms dictionary into the following schema (populated with example):\n",
    "    Args:\n",
    "    - file_path (str): relative file path\n",
    "\n",
    "\n",
    "    transformed_dict = {\"text\": \"Der Burger hat gut geschmeckt\", \n",
    "            \"tags\": [\n",
    "                {\"start\": 0, \"end\": 0, \"label\": \"food\", \"polarity\": \"positive\", \"type\": \"label-explicit\"},\n",
    "            ]}\n",
    "\n",
    "    - The aspect labels will be adjusted according to the labels used in the GERestaurant paper\n",
    "    - Explicit and implicit label types are added as Rest15/16 datasets do not provide these labels\n",
    "    - The dictionaries will passed to the XML-Tagger which will turn the dictionaries into xml-format for the TASD-Task \n",
    "    \"\"\"\n",
    "\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Labels mapped to the lables of the GERestaurant Paper\n",
    "    label_map = {\n",
    "            \"PRICES\": \"PRICE\",\n",
    "            \"RESTAURANT\" : \"GENERAL-IMPRESSION\",\n",
    "            \"LOCATION\" : \"AMBIENCE\",\n",
    "            \"DRINKS\" : \"FOOD\",\n",
    "            \"SERVICE\" : \"SERVICE\",\n",
    "            \"AMBIENCE\": \"AMBIENCE\",\n",
    "            \"FOOD\" : \"FOOD\"\n",
    "        }\n",
    "\n",
    "    # Transform the data\n",
    "    transformed_data = []\n",
    "\n",
    "    for sentence in root.findall(\".//sentence\"):\n",
    "        text = sentence.find(\"text\").text\n",
    "        tags = []\n",
    "        for opinion in sentence.findall(\".//Opinion\"):\n",
    "\n",
    "            # get Price label\n",
    "            label_check = opinion.attrib[\"category\"].split('#')\n",
    "            if \"PRICES\" in label_check:\n",
    "                opinion_label = \"PRICES\"\n",
    "            else:\n",
    "                opinion_label = opinion.attrib[\"category\"].split(\"#\")[0] # Extracting main label (e.g., \"FOOD\")\n",
    "\n",
    "            tag = {\n",
    "                \"start\": int(opinion.attrib[\"from\"]),\n",
    "                \"end\": int(opinion.attrib[\"to\"]),\n",
    "                \"label\": opinion_label,  \n",
    "                \"polarity\": opinion.attrib[\"polarity\"],\n",
    "                \"type\": \"label-explicit\"  # Static value as per example\n",
    "            }\n",
    "\n",
    "            if opinion.attrib['target'] == \"NULL\":\n",
    "                tag['type'] = \"label-implicit\"\n",
    "\n",
    "            # mapping categories to GERestaurant\n",
    "            original_label = tag['label']\n",
    "            ger_label = label_map[original_label]\n",
    "\n",
    "            # assign new label\n",
    "            tag['label'] = ger_label\n",
    "\n",
    "            tags.append(tag)\n",
    "\n",
    "        # ignore sentences that do not have any opinion tags\n",
    "        if not tags:\n",
    "            continue\n",
    "        else:\n",
    "            transformed_data.append({\"text\": text, \"tags\": tags})\n",
    "\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_list_to_json(list_dict: list, file_name: str) -> None:\n",
    "    \n",
    "    with open(f\"{file_name}.json\", \"w\", encoding='utf-8') as json_input:\n",
    "        json.dump(list_dict, json_input, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Nils Hellwig\n",
    "\n",
    "from collections import Counter\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "\n",
    "def convert_ner_to_xml(ner_dict):\n",
    "    text = ner_dict['text']\n",
    "    tags = ner_dict['tags']\n",
    "    tag_positions = []\n",
    "\n",
    "    for tag in tags:\n",
    "        start = tag['start']\n",
    "        end = tag['end']\n",
    "        label = tag['label']\n",
    "        polarity = tag['polarity']\n",
    "        tag_type = tag['type']\n",
    "\n",
    "        if tag_type == 'label-explicit':\n",
    "            tag_positions.append(\n",
    "                (start, f'<aspect-term aspect=\"{label}\" polarity=\"{polarity}\">'))\n",
    "            tag_positions.append((end, '</aspect-term>'))\n",
    "\n",
    "        # Add implicit labels\n",
    "        # Author: Lucas MÃ¼ller\n",
    "        if tag_type == 'label-implicit':\n",
    "            end_text = len(text) + 1\n",
    "            tag_positions.append(\n",
    "                (end_text, f'<aspect-term aspect=\"{label}\" polarity=\"{polarity}\"></aspect-term>'))\n",
    "            \n",
    "\n",
    "        \n",
    "    tag_positions.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    xml_text = list(text)\n",
    "    for position, tag in tag_positions:\n",
    "        xml_text.insert(position, tag)\n",
    "\n",
    "    \n",
    "\n",
    "    return ''.join(xml_text)\n",
    "\n",
    "\n",
    "def remove_xml_tags_from_string(str):\n",
    "    return re.sub(r'<.*?>', '', str)\n",
    "\n",
    "\n",
    "def remove_xml_tags(input_string):\n",
    "    return re.sub(r'<[^>]+>', '', input_string)\n",
    "\n",
    "\n",
    "def extract_aspect_polarity(xml_string):\n",
    "    aspect_match = re.search(r'aspect=\"([^\"]+)\"', xml_string)\n",
    "    polarity_match = re.search(r'polarity=\"([^\"]+)\"', xml_string)\n",
    "\n",
    "    aspect = aspect_match.group(1) if aspect_match else None\n",
    "    polarity = polarity_match.group(1) if polarity_match else None\n",
    "\n",
    "    return aspect, polarity\n",
    "\n",
    "\n",
    "def get_explicit_aspects(tags, predicted_text):\n",
    "\n",
    "    # 1. match position\n",
    "    pattern = r\"<aspect-term(?!.*<aspect-term).*?<\\/aspect-term>\"\n",
    "    matches = list(re.finditer(pattern, predicted_text))\n",
    "    if len(matches) == 0:\n",
    "        return tags, predicted_text  # Return tags and the updated text\n",
    "\n",
    "    match = matches[0]\n",
    "\n",
    "    # 2. position in text with tags\n",
    "    tag_xml = match.group()\n",
    "    tag_xml_start = match.start()\n",
    "    tag_xml_end = match.end()\n",
    "\n",
    "    # 3. identify aspect and polarity\n",
    "    aspect, polarity = extract_aspect_polarity(tag_xml)\n",
    "\n",
    "    # 4. position in text without tags\n",
    "    tag_text = remove_xml_tags(tag_xml)\n",
    "    tag_start = len(remove_xml_tags(predicted_text[0:match.start()]))\n",
    "    tag_end = tag_start + len(tag_text)\n",
    "\n",
    "    # 5. remove tag from text\n",
    "    predicted_text = predicted_text[0:tag_xml_start] + \\\n",
    "        tag_text + predicted_text[tag_xml_end:]\n",
    "\n",
    "    # 6. add tags to list\n",
    "    tags.append({\"text\": tag_text, \"start\": tag_start, \"end\": tag_end, \"tag_with_polarity\": aspect+\"-\"+polarity,\n",
    "                \"tag_with_polarity_and_type\": aspect+\"-\"+polarity+\"-explicit\", \"type\": \"label-explicit\", \"label\": aspect, \"polarity\": polarity})\n",
    "\n",
    "    # Recursive call\n",
    "    return get_explicit_aspects(tags, predicted_text)\n",
    "\n",
    "\n",
    "def check_difference_between_tags_in_synth_text_and_label(label, tags_synth):\n",
    "    \"\"\"\n",
    "    This function identifies the differences between aspect-polarity pairs in the label and the synthesised text.\n",
    "\n",
    "    Args:\n",
    "    label (list of tuples): The aspect-polarity pairs in the label.\n",
    "    tags_synth (list of tuples): The aspect-polarity pairs in the synthesised text.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two lists:\n",
    "        - List of aspect-polarity pairs present in the label but not in the synthesised text.\n",
    "        - List of aspect-polarity pairs present in the synthesised text but not in the label.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Count the occurrences of aspect-polarity pairs in the label and synthesised text\n",
    "    label_count = Counter(label)\n",
    "    tags_synth_count = Counter(tags_synth)\n",
    "    \n",
    "    # Find aspect-polarity pairs in the label but not in the synthesised text\n",
    "    not_in_tags_synth_count = [tup for tup, count in label_count.items() for _ in range(max(0, count - tags_synth_count.get(tup, 0)))]\n",
    "    \n",
    "    # Find aspect-polarity pairs in the synthesised text but not in the label\n",
    "    not_in_label = [tup for tup, count in tags_synth_count.items() if count > label_count.get(tup, 0)]\n",
    "    \n",
    "    return not_in_tags_synth_count, not_in_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tagged_reviews(list_of_reviews: list) -> list:\n",
    "    \"\"\"Validation of review sentences via RegEx\n",
    "    Args:\n",
    "    - list_of_reviews (str): list of dictionaries containing reviews\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # RegEx pattern for TASD-XML-Tags\n",
    "    # pattern = r\"<aspect-term\\s+aspect=\\\"(?:GENERAL-IMPRESSION|FOOD|AMBIENCE|SERVICE|PRICE)\\\"\\s+polarity=\\\"(?:negative|positive|neutral)\\\">.*?</aspect-term>\"\n",
    "\n",
    "    list_sent = []\n",
    "    \n",
    "    for review in list_of_reviews:\n",
    "        try:\n",
    "            tasd_sent = convert_ner_to_xml(review)\n",
    "            if re.search(pattern, tasd_sent):\n",
    "                list_sent.append(tasd_sent)\n",
    "            else:\n",
    "                raise Exception(f\"Sentence found not valid: {tasd_sent}\")\n",
    "        except Exception as e:\n",
    "                print(f\"Invalid Sentence caught: {e}\")\n",
    "                break\n",
    "\n",
    "    return list_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_xml(list_of_sentences: list, file_name: str) -> None:\n",
    "    \"\"\"Converts List of strings to XML-file\n",
    "    Args:\n",
    "    - list_of_sentences (str): List containing validated sentences\n",
    "    - file_name (str): file name for saving file\n",
    "    \"\"\"\n",
    "\n",
    "    sentence_tag_start = '<sentence>'\n",
    "    sentence_tag_end = '</sentence>'\n",
    "\n",
    "    list_tagged = []\n",
    "\n",
    "    for sentence in list_of_sentences:\n",
    "        tagged = sentence_tag_start + sentence + sentence_tag_end\n",
    "        list_tagged.append(tagged)\n",
    "\n",
    "    xml_string_file = ''.join(list_tagged)\n",
    "    xml_string_file = \"<?xml version='1.0' encoding='utf-8'?>\" + \"<Reviews>\" + xml_string_file + \"</Reviews>\"\n",
    "\n",
    "    # replace ampersand due to validation conflicts\n",
    "    xml_string_file = re.sub('&', \"'\", xml_string_file)\n",
    "\n",
    "    with open(\"test.txt\", \"w\") as f:\n",
    "        f.write(xml_string_file)\n",
    "\n",
    "\n",
    "    tree = ET.ElementTree(ET.fromstring(xml_string_file))\n",
    "\n",
    "    # Write to file\n",
    "    tree.write(f\"{file_name}.xml\", encoding='utf-8')\n",
    "\n",
    "\n",
    "    # Prettify XML-file\n",
    "    with open(f\"{file_name}.xml\", \"r\", encoding=\"utf-8\") as file:\n",
    "        xml_string = file.read()\n",
    "\n",
    "    # Parse and pretty-print\n",
    "    xml_doc = xml.dom.minidom.parseString(xml_string)\n",
    "    pretty_xml = xml_doc.toprettyxml(indent=\"  \")\n",
    "\n",
    "    # Optionally, save the beautified XML to a new file\n",
    "    with open(f\"{file_name}.xml\", \"w\", encoding='utf-8') as file:\n",
    "        file.write(pretty_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml_file_path_rest15 = \"..\\\\data\\\\original_data\\\\test\\\\ABSA15_Restaurants_Test.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_path_train15 = \"..\\\\data\\\\original_data\\\\train\\\\ABSA-15_Restaurants_Train_Final.xml\"\n",
    "xml_file_path_train16 = \"..\\\\data\\\\original_data\\\\train\\\\ABSA16_Restaurants_Train_SB1_v2.xml\"\n",
    "\n",
    "xml_file_path_test16 = \"..\\\\data\\\\original_data\\\\test\\\\EN_REST16_SB1_TEST_GOLD.xml\"\n",
    "xml_file_path_test15 = \"..\\\\data\\\\original_data\\\\test\\\\ABSA15_Restaurants_Test.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"TASD_REST15_TRAIN\": xml_file_path_train15,\n",
    "    \"TASD_REST16_TRAIN\": xml_file_path_train16,\n",
    "    \"TASD_REST15_TEST\": xml_file_path_test15,\n",
    "    \"TASD_REST16_TEST\": xml_file_path_test16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file_name,file_path in file_paths.items():\n",
    "\n",
    "    list_sent = []\n",
    "    \n",
    "    transformed_data_rest = xml_to_dict_list(file_path)\n",
    "    for review in transformed_data_rest:\n",
    "        list_sent.append(convert_ner_to_xml(review))\n",
    "\n",
    "    string_to_xml(list_sent, file_name)\n",
    "# print(f\"Number of valid reviews for Rest15: {len(list_sent)}\") # 1120 valid reviews\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
